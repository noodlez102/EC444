#Talk2Car

Authors: Kevin Chen, Arthur Hua, Sam Qiu

Date: 2024-10-04

### Summary
In this quest we learned how to move the rc car using the esp32 and an h bridge to bring up the signals so the rc servos can read it. Using the skills we learned from previous skills such as hooking up a lidar and ir sensor to helpt detect where the car is to help prevent collisions with walls and make sure the rc car is driving straight. We also learned how to implement speech to text so we can talk to the car with python and then by using udp issue commands to the car for it preform certain tasks that is specified.

### Self-Assessment 

| Objective Criterion | Rating | Max Value  | 
|---------------------------------------------|:-----------:|:---------:|
|Controls steering to maintain center of course +/- 25cm for entire length |1  |  1     | 
| Uses PID for speed control holding a fixed speed setpoint after startup and before slowdown [0.1-0.4 m/s]| 1 |  1     | 
| Stops within 20 cm of end without collision |1  |  1     | 
|Start and stop instructions issued wirelessly from phone, laptop | 1 |  1     | 
| Measures wheel speed or distance| 1 |  1     | 
| Uses alpha display to show current distance or speed | 1 |  1     | 
| Successfully traverses A-B in one go, no hits or nudges | 1 |  1     | 


### Solution Design
We created a car that was capable of maintaining a straight path and consistent speed with pid using a lidar for distance and a photosensor for wheelspeed. the car was able to start/stop utilizing python speech to text transferring words over wifi using udp. TO support collision control we utilized a ir sensor to measure the distance of objects ahead and prevent collisions by stopping the vehicle. 

### Investigative Question
If we were asked to provide a more 'adaptive' cruise control, to us that means is the car could more easily respond to different situations, so we would place more sensors on our car and program it so that it would be able to respond to different situations. I would additionally use some sort of camera to help facilitate the ability to differentiate between situations.  





### Supporting Artifacts
- [Link to video technical presentation](https://youtu.be/zupSNCrBNUA?si=oNGlBLJ6h--fvFhb). Not to exceed 120s
- [Link to video demo](https://youtu.be/q7Yoam1wpM0?si=WT_fKM8R35DLEsWs). Not to exceed 120s

### here are supporting images
![img](https://github.com/BU-EC444/Team02-Hua-Chen-Qiu/blob/main/quest-4/images/image_50729217.JPG)

![img](https://github.com/BU-EC444/Team02-Hua-Chen-Qiu/blob/main/quest-4/images/pid_speed.png)

![img](https://github.com/BU-EC444/Team02-Hua-Chen-Qiu/blob/main/quest-4/images/python_speech_command_communication.png)
















### Modules, Tools, Source Used Including Attribution

### AI Use
for speech to text and includes:


I used {chat.openai.com GPT-3.5} on {8/30/2023} with the following prompt:

***Prompt***

``` 


*** write python code for recieving and sending udp packets
please consolidate the includes




{prompt}

```

***Code Attribution***

I have included a comment in my code for this assignment stating the following:

```
// This code block was generated by {name} using {chat.openai.com
GPT-3.5} on {8/30/2023}

```

